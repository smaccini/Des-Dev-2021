{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "print(\"Lets's start coding...\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lets's start coding...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "print(\"Time for dictionaries!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time for dictionaries!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print(\"And sorting!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "And sorting!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# For this exercise, you should start by reading in the text file produced from Exercise Three. \r\n",
    "# This text file should already have the HTML code elements removed, and primarily consist of text and other characters that we will remove through our processing. \r\n",
    "# Store the input of your file in a string, and convert the contents to lower case for consistency.\r\n",
    "\r\n",
    "# open the txt file to read it\r\n",
    "f = open(\"NPRarticlecleaned.txt\",\"r\")\r\n",
    "\r\n",
    "# create new variable with contents\r\n",
    "NPRtextWeek4 = f.read()\r\n",
    "print(NPRtextWeek4[0:200])\r\n",
    "f.close()\r\n",
    "\r\n",
    "# covert to lower\r\n",
    "\r\n",
    "NPRcleanedlower = NPRtextWeek4.lower()\r\n",
    "print(NPRcleanedlower[0:200])\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Torey Edmonds has lived in the same house in an African-American neighborhood of the East End of Richmond, Va., for all of her 61 years. When she was a little girl, she says her neighborhood was a pla\n",
      "torey edmonds has lived in the same house in an african-american neighborhood of the east end of richmond, va., for all of her 61 years. when she was a little girl, she says her neighborhood was a pla\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# This week, we'll be using functions that we've already defined in our exercises. \r\n",
    "# Try looking back through your code and notes from class. Our first step is to import the regular expressions module and remove all non-alpha-numeric characters from the string, \r\n",
    "# then save the string as an array of words ready for processing. \r\n",
    "# (Use the code in NormalizingText for reference)\r\n",
    "\r\n",
    "# In class, we did these in reverse order, and I am going to stick with the order used in class.\r\n",
    "\r\n",
    "# Creating the bag of words array\r\n",
    "NPR_word_bag = NPRcleanedlower.split()\r\n",
    "print(NPR_word_bag[0:200])\r\n",
    "\r\n",
    "\r\n",
    "# Remove non-alpha-numeric characters\r\n",
    "\r\n",
    "import re\r\n",
    "NPR_word_bag = re.compile(r'\\W+', re.UNICODE).split(NPRcleanedlower)\r\n",
    "print(NPR_word_bag[0:200])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['torey', 'edmonds', 'has', 'lived', 'in', 'the', 'same', 'house', 'in', 'an', 'african-american', 'neighborhood', 'of', 'the', 'east', 'end', 'of', 'richmond,', 'va.,', 'for', 'all', 'of', 'her', '61', 'years.', 'when', 'she', 'was', 'a', 'little', 'girl,', 'she', 'says', 'her', 'neighborhood', 'was', 'a', 'place', 'of', 'tidy', 'homes', 'with', 'rose', 'bushes', 'and', 'fruit', 'trees,', 'and', 'residents', 'had', 'ready', 'access', 'to', 'shops', 'like', 'beauty', 'salons,', 'movie', 'theaters', 'and', 'several', 'grocery', 'stores.', 'but', 'as', 'she', 'grew', 'up,', 'she', 'says,', 'the', 'neighborhood', 'went', 'downhill.', 'by', 'the', '1970s,', 'stores', 'had', 'disappeared;', 'those', 'that', 'did', 'return', 'were', 'corner', 'shops', 'selling', 'cheap', 'alcohol', 'but', '\"no', 'real', 'food,\"', 'edmonds', 'says.', 'houses', 'declined', 'too,', 'as', 'homeowners', '\\\\xe2\\\\x80\\\\x93', 'including', 'her', 'parents', '\\\\xe2\\\\x80\\\\x93', 'were', 'rejected', 'for', 'loans.', '\"if', 'the', \"bank\\\\'s\", 'not', 'loaning,', 'she', 'says,', '\"then', 'things', 'deteriorate.\"', 'today,', \"edmonds\\\\'\", 'neighborhood', 'remains', 'overwhelmingly', 'african-american,', 'with', 'a', 'poverty', 'rate', 'of', 'nearly', '60%.', 'many', 'of', 'her', 'neighbors', 'suffer', 'chronic', 'medical', 'conditions', 'like', 'kidney', 'disease', 'and', 'diabetes.', '\"they', 'age', 'differently,\"', 'says', 'edmonds,', 'who', 'works', 'for', 'virginia', 'commonwealth', 'university', 'promoting', 'community', 'health.', '\"we', 'have', 'a', 'lot', 'of', 'our', 'neighbors', 'that', 'have', 'health', 'challenges.\"', '\\\\n', '\\\\n\\\\n', '\\\\n\\\\n', '\\\\n', 'loading...', '\\\\n', '\\\\n', '\\\\n\\\\n', 'but', \"it\\\\'s\", 'not', 'just', \"edmonds\\\\'\", 'neighborhood.', 'in', 'city', 'after', 'city', 'across', 'the', 'u.s.,', 'from', 'milwaukee', 'to', 'miami,', 'researchers', 'have', 'found', 'a']\n",
      "['torey', 'edmonds', 'has', 'lived', 'in', 'the', 'same', 'house', 'in', 'an', 'african', 'american', 'neighborhood', 'of', 'the', 'east', 'end', 'of', 'richmond', 'va', 'for', 'all', 'of', 'her', '61', 'years', 'when', 'she', 'was', 'a', 'little', 'girl', 'she', 'says', 'her', 'neighborhood', 'was', 'a', 'place', 'of', 'tidy', 'homes', 'with', 'rose', 'bushes', 'and', 'fruit', 'trees', 'and', 'residents', 'had', 'ready', 'access', 'to', 'shops', 'like', 'beauty', 'salons', 'movie', 'theaters', 'and', 'several', 'grocery', 'stores', 'but', 'as', 'she', 'grew', 'up', 'she', 'says', 'the', 'neighborhood', 'went', 'downhill', 'by', 'the', '1970s', 'stores', 'had', 'disappeared', 'those', 'that', 'did', 'return', 'were', 'corner', 'shops', 'selling', 'cheap', 'alcohol', 'but', 'no', 'real', 'food', 'edmonds', 'says', 'houses', 'declined', 'too', 'as', 'homeowners', 'xe2', 'x80', 'x93', 'including', 'her', 'parents', 'xe2', 'x80', 'x93', 'were', 'rejected', 'for', 'loans', 'if', 'the', 'bank', 's', 'not', 'loaning', 'she', 'says', 'then', 'things', 'deteriorate', 'today', 'edmonds', 'neighborhood', 'remains', 'overwhelmingly', 'african', 'american', 'with', 'a', 'poverty', 'rate', 'of', 'nearly', '60', 'many', 'of', 'her', 'neighbors', 'suffer', 'chronic', 'medical', 'conditions', 'like', 'kidney', 'disease', 'and', 'diabetes', 'they', 'age', 'differently', 'says', 'edmonds', 'who', 'works', 'for', 'virginia', 'commonwealth', 'university', 'promoting', 'community', 'health', 'we', 'have', 'a', 'lot', 'of', 'our', 'neighbors', 'that', 'have', 'health', 'challenges', 'n', 'n', 'n', 'n', 'n', 'n', 'loading', 'n', 'n', 'n', 'n', 'but', 'it', 's', 'not', 'just', 'edmonds', 'neighborhood', 'in', 'city', 'after', 'city']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Next, we'll use stop words to remove all the words that we don't want to include in our count. \r\n",
    "# There are suggested words in this week's readings, but you can also generate a custom list based on your topic. Define the stop words in an array, \r\n",
    "# and use a loop to remove any word in your bag of words that also appears on the stop words list (use the examples in Dictionaries for guidance.)\r\n",
    "\r\n",
    "# Using stopwords from Turkel list plus adding a few more that seem to be clutter to my list\r\n",
    "\r\n",
    "stopwords = ['a', 'about', 'above', 'across', 'after', 'afterwards']\r\n",
    "stopwords += ['again', 'against', 'all', 'almost', 'alone', 'along']\r\n",
    "stopwords += ['already', 'also', 'although', 'always', 'am', 'among']\r\n",
    "stopwords += ['amongst', 'amoungst', 'amount', 'an', 'and', 'another']\r\n",
    "stopwords += ['any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere']\r\n",
    "stopwords += ['are', 'around', 'as', 'at', 'back', 'be', 'became']\r\n",
    "stopwords += ['because', 'become', 'becomes', 'becoming', 'been']\r\n",
    "stopwords += ['before', 'beforehand', 'behind', 'being', 'below']\r\n",
    "stopwords += ['beside', 'besides', 'between', 'beyond', 'bill', 'both']\r\n",
    "stopwords += ['bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant']\r\n",
    "stopwords += ['co', 'computer', 'con', 'could', 'couldnt', 'cry', 'de']\r\n",
    "stopwords += ['describe', 'detail', 'did', 'do', 'done', 'down', 'due']\r\n",
    "stopwords += ['during', 'each', 'eg', 'eight', 'either', 'eleven', 'else']\r\n",
    "stopwords += ['elsewhere', 'empty', 'enough', 'etc', 'even', 'ever']\r\n",
    "stopwords += ['every', 'everyone', 'everything', 'everywhere', 'except']\r\n",
    "stopwords += ['few', 'fifteen', 'fifty', 'fill', 'find', 'fire', 'first']\r\n",
    "stopwords += ['five', 'for', 'former', 'formerly', 'forty', 'found']\r\n",
    "stopwords += ['four', 'from', 'front', 'full', 'further', 'get', 'give']\r\n",
    "stopwords += ['go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her']\r\n",
    "stopwords += ['here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers']\r\n",
    "stopwords += ['herself', 'him', 'himself', 'his', 'how', 'however']\r\n",
    "stopwords += ['hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed']\r\n",
    "stopwords += ['interest', 'into', 'is', 'it', 'its', 'itself', 'keep']\r\n",
    "stopwords += ['last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made']\r\n",
    "stopwords += ['many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine']\r\n",
    "stopwords += ['more', 'moreover', 'most', 'mostly', 'move', 'much']\r\n",
    "stopwords += ['must', 'my', 'myself', 'name', 'namely', 'neither', 'never']\r\n",
    "stopwords += ['nevertheless', 'next', 'nine', 'no', 'nobody', 'none']\r\n",
    "stopwords += ['noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of']\r\n",
    "stopwords += ['off', 'often', 'on','once', 'one', 'only', 'onto', 'or']\r\n",
    "stopwords += ['other', 'others', 'otherwise', 'our', 'ours', 'ourselves']\r\n",
    "stopwords += ['out', 'over', 'own', 'part', 'per', 'perhaps', 'please']\r\n",
    "stopwords += ['put', 'rather', 're', 's', 'same', 'see', 'seem', 'seemed']\r\n",
    "stopwords += ['seeming', 'seems', 'serious', 'several', 'she', 'should']\r\n",
    "stopwords += ['show', 'side', 'since', 'sincere', 'six', 'sixty', 'so']\r\n",
    "stopwords += ['some', 'somehow', 'someone', 'something', 'sometime']\r\n",
    "stopwords += ['sometimes', 'somewhere', 'still', 'such', 'system', 'take']\r\n",
    "stopwords += ['ten', 'than', 'that', 'the', 'their', 'them', 'themselves']\r\n",
    "stopwords += ['then', 'thence', 'there', 'thereafter', 'thereby']\r\n",
    "stopwords += ['therefore', 'therein', 'thereupon', 'these', 'they']\r\n",
    "stopwords += ['thick', 'thin', 'third', 'this', 'those', 'though', 'three']\r\n",
    "stopwords += ['three', 'through', 'throughout', 'thru', 'thus', 'to']\r\n",
    "stopwords += ['together', 'too', 'top', 'toward', 'towards', 'twelve']\r\n",
    "stopwords += ['twenty', 'two', 'un', 'under', 'until', 'up', 'upon']\r\n",
    "stopwords += ['us', 'very', 'via', 'was', 'we', 'well', 'were', 'what']\r\n",
    "stopwords += ['whatever', 'when', 'whence', 'whenever', 'where']\r\n",
    "stopwords += ['whereafter', 'whereas', 'whereby', 'wherein', 'whereupon']\r\n",
    "stopwords += ['wherever', 'whether', 'which', 'while', 'whither', 'who']\r\n",
    "stopwords += ['whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with']\r\n",
    "stopwords += ['within', 'without', 'would', 'yet', 'you', 'your']\r\n",
    "stopwords += ['yours', 'yourself', 'yourselves']\r\n",
    "stopwords += ['xe2','x80','x93','max','posner','npr','toggle','hide','caption','enlarge','image','n']\r\n",
    "\r\n",
    "def removeStopWords(NPR_word_bag, stopwords):\r\n",
    "    return [w for w in NPR_word_bag if w not in stopwords]\r\n",
    "NPRArticle_words = removeStopWords(NPR_word_bag, stopwords)\r\n",
    "print(NPRArticle_words[0:200])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['torey', 'edmonds', 'lived', 'house', 'african', 'american', 'neighborhood', 'east', 'end', 'richmond', 'va', '61', 'years', 'little', 'girl', 'says', 'neighborhood', 'place', 'tidy', 'homes', 'rose', 'bushes', 'fruit', 'trees', 'residents', 'ready', 'access', 'shops', 'like', 'beauty', 'salons', 'movie', 'theaters', 'grocery', 'stores', 'grew', 'says', 'neighborhood', 'went', 'downhill', '1970s', 'stores', 'disappeared', 'return', 'corner', 'shops', 'selling', 'cheap', 'alcohol', 'real', 'food', 'edmonds', 'says', 'houses', 'declined', 'homeowners', 'including', 'parents', 'rejected', 'loans', 'bank', 'loaning', 'says', 'things', 'deteriorate', 'today', 'edmonds', 'neighborhood', 'remains', 'overwhelmingly', 'african', 'american', 'poverty', 'rate', 'nearly', '60', 'neighbors', 'suffer', 'chronic', 'medical', 'conditions', 'like', 'kidney', 'disease', 'diabetes', 'age', 'differently', 'says', 'edmonds', 'works', 'virginia', 'commonwealth', 'university', 'promoting', 'community', 'health', 'lot', 'neighbors', 'health', 'challenges', 'loading', 'just', 'edmonds', 'neighborhood', 'city', 'city', 'u', 'milwaukee', 'miami', 'researchers', 'disturbing', 'pattern', 'people', 'live', 'neighborhoods', 'subjected', 'discriminatory', 'lending', 'practice', 'called', 'redlining', 'today', 'likely', 'experience', 'shorter', 'life', 'spans', '20', '30', 'years', 'shorter', 'neighborhoods', 'city', 'researchers', 'national', 'community', 'reinvestment', 'coalition', 'university', 'richmond', 'university', 'wisconsin', 'milwaukee', 'analyzed', 'historic', 'redlining', 'maps', '142', 'urban', 'areas', 'u', 'x94', 'maps', 'created', '1930s', 'classified', 'black', 'immigrant', 'communities', 'risky', 'places', 'make', 'home', 'loans', 'compared', 'maps', 'current', 'economic', 'status', 'health', 'outcomes', 'neighborhoods', 'today', 'higher', 'rates', 'poverty', 'shorter', 'life', 'spans', 'higher', 'rates', 'chronic', 'diseases', 'including', 'asthma', 'diabetes', 'hypertension', 'obesity', 'kidney', 'disease', 'redlined', 'neighborhoods', 'likely', 'greater', 'social', 'vulnerability', 'meaning', 'able', 'withstand', 'natural']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Now we're ready to count our words, and move from an array to a dictionary. \r\n",
    "# Using the functions we've already built in the \"Dictionaries.ipynb\" file, # process your text by building a dictionary that zips words with their frequency, \r\n",
    "# then removes redundancy by storing the data in the \"dictionary\" format.\r\n",
    "\r\n",
    "def wordsToDictionary(NPRArticle_words):\r\n",
    "    word_freq = [NPRArticle_words.count(word) for word in NPRArticle_words]\r\n",
    "    return dict(list(zip(NPRArticle_words,word_freq)))\r\n",
    "\r\n",
    "\r\n",
    "counted_words = wordsToDictionary(NPRArticle_words)\r\n",
    "print(counted_words)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'torey': 1, 'edmonds': 7, 'lived': 1, 'house': 1, 'african': 4, 'american': 5, 'neighborhood': 10, 'east': 1, 'end': 2, 'richmond': 16, 'va': 3, '61': 1, 'years': 6, 'little': 1, 'girl': 1, 'says': 25, 'place': 1, 'tidy': 1, 'homes': 1, 'rose': 1, 'bushes': 1, 'fruit': 1, 'trees': 2, 'residents': 1, 'ready': 1, 'access': 3, 'shops': 2, 'like': 4, 'beauty': 1, 'salons': 1, 'movie': 1, 'theaters': 1, 'grocery': 2, 'stores': 3, 'grew': 1, 'went': 1, 'downhill': 1, '1970s': 1, 'disappeared': 1, 'return': 1, 'corner': 1, 'selling': 1, 'cheap': 1, 'alcohol': 1, 'real': 1, 'food': 2, 'houses': 4, 'declined': 2, 'homeowners': 2, 'including': 5, 'parents': 1, 'rejected': 1, 'loans': 4, 'bank': 1, 'loaning': 1, 'things': 1, 'deteriorate': 1, 'today': 8, 'remains': 1, 'overwhelmingly': 1, 'poverty': 3, 'rate': 1, 'nearly': 1, '60': 1, 'neighbors': 3, 'suffer': 1, 'chronic': 2, 'medical': 1, 'conditions': 2, 'kidney': 2, 'disease': 2, 'diabetes': 2, 'age': 1, 'differently': 1, 'works': 1, 'virginia': 1, 'commonwealth': 1, 'university': 13, 'promoting': 2, 'community': 8, 'health': 21, 'lot': 1, 'challenges': 1, 'loading': 2, 'just': 5, 'city': 7, 'u': 5, 'milwaukee': 5, 'miami': 1, 'researchers': 7, 'disturbing': 1, 'pattern': 1, 'people': 2, 'live': 2, 'neighborhoods': 15, 'subjected': 1, 'discriminatory': 2, 'lending': 2, 'practice': 3, 'called': 1, 'redlining': 24, 'likely': 5, 'experience': 1, 'shorter': 3, 'life': 5, 'spans': 2, '20': 1, '30': 1, 'national': 3, 'reinvestment': 3, 'coalition': 3, 'wisconsin': 4, 'analyzed': 3, 'historic': 3, 'maps': 13, '142': 1, 'urban': 6, 'areas': 8, 'x94': 4, 'created': 2, '1930s': 5, 'classified': 1, 'black': 2, 'immigrant': 1, 'communities': 8, 'risky': 3, 'places': 2, 'make': 1, 'home': 2, 'compared': 1, 'current': 1, 'economic': 1, 'status': 1, 'outcomes': 7, 'higher': 3, 'rates': 2, 'diseases': 1, 'asthma': 1, 'hypertension': 1, 'obesity': 1, 'redlined': 11, 'greater': 3, 'social': 4, 'vulnerability': 3, 'meaning': 4, 'able': 3, 'withstand': 3, 'natural': 3, 'human': 3, 'disasters': 3, 'limited': 3, 'resources': 4, 'published': 1, 'interactive': 2, 'versions': 1, 'online': 1, 'public': 4, 'explore': 1, 'mapped': 1, 'graphics': 1, 'allow': 1, 'ranked': 1, 'fares': 1, 'makes': 1, 'findings': 5, 'especially': 1, 'urgent': 1, 'note': 1, 'levels': 1, 'raise': 1, 'risk': 3, 'severe': 1, 'covid': 2, '19': 2, 'startling': 1, 'revelation': 1, 'global': 1, 'pandemic': 2, 'going': 2, 'impact': 2, 'official': 1, 'policy': 4, 'jason': 1, 'richardson': 2, 'research': 3, 'director': 2, 'ncrc': 2, 'author': 3, 'study': 6, 'federally': 1, 'sanctioned': 1, 'discrimination': 1, 'originated': 1, 'aftermath': 1, 'great': 1, 'depression': 1, 'federal': 8, 'government': 5, 'set': 2, 'evaluate': 1, 'riskiness': 1, 'mortgages': 1, 'major': 2, 'metropolitan': 1, 'country': 1, 'owners': 1, 'loan': 1, 'corporation': 1, 'color': 5, 'coded': 1, 'credit': 1, 'worthiness': 1, 'americans': 1, 'immigrants': 3, 'considered': 3, 'highest': 3, 'marked': 1, 'red': 3, 'map': 2, '1930': 2, 'outlined': 2, 'mortgage': 2, 'lenders': 3, 'offer': 3, 'digital': 4, 'scholarship': 4, 'lab': 4, 'difficult': 3, 'impossible': 3, 'buy': 3, 'refinance': 3, 'lack': 4, 'investment': 3, 'meant': 5, 'fell': 3, 'disrepair': 3, 'housing': 5, 'policies': 5, 'time': 2, 'helped': 4, 'concentrate': 1, 'generations': 2, 'banks': 1, 'actors': 1, 'discouraged': 1, 'kind': 2, 'predictable': 1, 'arc': 1, 'stop': 1, 'think': 2, 'm': 1, 'shocked': 1, 'lingering': 1, 'led': 1, 'hazards': 1, 'mold': 1, 'lead': 1, 'paint': 1, 'industrial': 1, 'sites': 1, 'located': 1, 'near': 1, 'exposure': 2, 'pollution': 1, 'retailers': 1, 'left': 1, 'healthy': 1, 'parks': 1, 'green': 1, 'spaces': 1, 'fewer': 2, 'exercise': 1, 'factors': 1, 'combined': 1, 'create': 3, 'environment': 2, 'conducive': 1, 'poorer': 1, 'say': 2, 'impacts': 2, 'opportunities': 2, 'helen': 1, 'meier': 1, 'epidemiologist': 1, 'systematically': 1, 'shaped': 1, 'characteristics': 1, 'built': 1, 'ways': 2, 'impacting': 1, 'come': 1, 'surprise': 1, 'trust': 1, 'know': 1, 'average': 3, 'expectancy': 3, '68': 3, '21': 1, 'predominantly': 1, 'white': 3, 'miles': 1, 'away': 1, 'west': 1, 'got': 1, 'rating': 2, 'point': 1, 'zip': 1, 'code': 1, '23223': 1, 'number': 1, 'cases': 1, 'dr': 2, 'lisa': 1, 'cooper': 3, 'disparities': 1, 'researcher': 1, 'johns': 1, 'hopkins': 1, 'bloomberg': 1, 'school': 2, 'involved': 2, 'result': 2, 'individual': 1, 'choices': 2, 'baked': 1, 'fabric': 1, 'cities': 2, 'racist': 3, 'long': 1, 'ago': 1, 'happened': 1, 'born': 1, 'wouldn': 1, 't': 4, 'predicament': 1, 'notes': 1, 'large': 1, 'body': 1, 'linking': 1, 'residential': 2, 'segregation': 2, 'negative': 1, 'effects': 1, 'concentration': 1, 'disadvantage': 1, 'structural': 2, 'racism': 3, 'illustrated': 1, 'played': 1, 'role': 1, 'shaping': 1, 'demographics': 1, 'modern': 3, 'robert': 1, 'nelson': 4, 'historian': 1, 'focuses': 1, 'race': 1, 'underlying': 1, 'decisions': 1, 'undeniable': 1, 'project': 1, 'visualizes': 1, 'juxtaposes': 1, 'comments': 1, 'surveyors': 1, 'rated': 1, 'day': 1, 'indicators': 1, 'infiltration': 1, 'negroes': 1, 'common': 1, 'reason': 1, 'cited': 1, 'explain': 1, 'area': 1, 'high': 1, 'attitudes': 1, 'documents': 1, 'didn': 1, 'cement': 1, 'standard': 1, 'private': 1, 'followed': 1, 'want': 1, 'example': 3, 'systemic': 1, 'looks': 1, 'really': 2, 'aren': 1, 'better': 1, 'segregationist': 1, 'turn': 1, 'families': 5, 'moved': 1, 'suburbs': 1, 'leaving': 1, 'particularly': 1, 'later': 1, 'ended': 1, 'pushed': 1, 'projects': 1, 'way': 1, 'build': 1, 'intergenerational': 1, 'wealth': 1, 'cut': 1, 'outlawed': 1, '1968': 1, 'fair': 1, 'act': 1, 'damage': 1, 'links': 6, 'digitized': 1, '2016': 1, 'studies': 3, 'examined': 1, 'specific': 1, 'regions': 1, 'nancy': 1, 'krieger': 4, 'professor': 1, 'epidemiology': 1, 'harvard': 1, 'h': 1, 'chan': 1, 'work': 2, 'preterm': 1, 'births': 1, 'new': 1, 'york': 1, 'late': 1, 'stage': 1, 'cancer': 1, 'diagnoses': 1, 'massachusetts': 1, 'tend': 1, 'hotter': 1, 'non': 1, 'previously': 1, 'reported': 1, 'fairfield': 2, 'old': 2, 'partner': 1, 'universities': 1, 'important': 1, 'nationwide': 1, 'look': 1, 'range': 1, 'emphasize': 1, 'past': 1, 'ongoing': 1, 'ramifications': 1, 'history': 2, 'goodbye': 1, 'quoting': 1, 'uruguyan': 1, 'writer': 1, 'eduardo': 1, 'galeano': 1, '': 1}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Finally, explore what you can learn from this dictionary. Try: \r\n",
    "# A. Sorting your dictionary using our prebuilt method\r\n",
    "\r\n",
    "\r\n",
    "def sortDictionary(counted_words):\r\n",
    "    aux = [(counted_words[key], key) for key in counted_words]\r\n",
    "    aux.sort()\r\n",
    "    aux.reverse()\r\n",
    "    return aux\r\n",
    "\r\n",
    "sorted_counted_words = sortDictionary(counted_words)\r\n",
    "print(sorted_counted_words)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# B. Printing the top five most frequent words from your data\r\n",
    "\r\n",
    "\r\n",
    "# C. Querying for certain key words and printing their frequency\r\n",
    "# D. Comparing the relative frequency of words of interest\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(25, 'says'), (24, 'redlining'), (21, 'health'), (16, 'richmond'), (15, 'neighborhoods'), (13, 'university'), (13, 'maps'), (11, 'redlined'), (10, 'neighborhood'), (8, 'today'), (8, 'federal'), (8, 'community'), (8, 'communities'), (8, 'areas'), (7, 'researchers'), (7, 'outcomes'), (7, 'edmonds'), (7, 'city'), (6, 'years'), (6, 'urban'), (6, 'study'), (6, 'links'), (5, 'u'), (5, 'policies'), (5, 'milwaukee'), (5, 'meant'), (5, 'likely'), (5, 'life'), (5, 'just'), (5, 'including'), (5, 'housing'), (5, 'government'), (5, 'findings'), (5, 'families'), (5, 'color'), (5, 'american'), (5, '1930s'), (4, 'x94'), (4, 'wisconsin'), (4, 't'), (4, 'social'), (4, 'scholarship'), (4, 'resources'), (4, 'public'), (4, 'policy'), (4, 'nelson'), (4, 'meaning'), (4, 'loans'), (4, 'like'), (4, 'lack'), (4, 'lab'), (4, 'krieger'), (4, 'houses'), (4, 'helped'), (4, 'digital'), (4, 'african'), (3, 'withstand'), (3, 'white'), (3, 'vulnerability'), (3, 'va'), (3, 'studies'), (3, 'stores'), (3, 'shorter'), (3, 'risky'), (3, 'risk'), (3, 'research'), (3, 'reinvestment'), (3, 'refinance'), (3, 'red'), (3, 'racist'), (3, 'racism'), (3, 'practice'), (3, 'poverty'), (3, 'offer'), (3, 'neighbors'), (3, 'natural'), (3, 'national'), (3, 'modern'), (3, 'limited'), (3, 'lenders'), (3, 'investment'), (3, 'impossible'), (3, 'immigrants'), (3, 'human'), (3, 'historic'), (3, 'highest'), (3, 'higher'), (3, 'greater'), (3, 'fell'), (3, 'expectancy'), (3, 'example'), (3, 'disrepair'), (3, 'disasters'), (3, 'difficult'), (3, 'create'), (3, 'cooper'), (3, 'considered'), (3, 'coalition'), (3, 'buy'), (3, 'average'), (3, 'author'), (3, 'analyzed'), (3, 'access'), (3, 'able'), (3, '68'), (2, 'work'), (2, 'ways'), (2, 'trees'), (2, 'time'), (2, 'think'), (2, 'structural'), (2, 'spans'), (2, 'shops'), (2, 'set'), (2, 'segregation'), (2, 'school'), (2, 'say'), (2, 'richardson'), (2, 'result'), (2, 'residential'), (2, 'really'), (2, 'rating'), (2, 'rates'), (2, 'promoting'), (2, 'places'), (2, 'people'), (2, 'pandemic'), (2, 'outlined'), (2, 'opportunities'), (2, 'old'), (2, 'ncrc'), (2, 'mortgage'), (2, 'map'), (2, 'major'), (2, 'loading'), (2, 'live'), (2, 'lending'), (2, 'kind'), (2, 'kidney'), (2, 'involved'), (2, 'interactive'), (2, 'impacts'), (2, 'impact'), (2, 'homeowners'), (2, 'home'), (2, 'history'), (2, 'grocery'), (2, 'going'), (2, 'generations'), (2, 'food'), (2, 'fewer'), (2, 'fairfield'), (2, 'exposure'), (2, 'environment'), (2, 'end'), (2, 'dr'), (2, 'disease'), (2, 'discriminatory'), (2, 'director'), (2, 'diabetes'), (2, 'declined'), (2, 'created'), (2, 'covid'), (2, 'conditions'), (2, 'cities'), (2, 'chronic'), (2, 'choices'), (2, 'black'), (2, '1930'), (2, '19'), (1, 'zip'), (1, 'york'), (1, 'writer'), (1, 'wouldn'), (1, 'worthiness'), (1, 'works'), (1, 'west'), (1, 'went'), (1, 'wealth'), (1, 'way'), (1, 'want'), (1, 'visualizes'), (1, 'virginia'), (1, 'versions'), (1, 'uruguyan'), (1, 'urgent'), (1, 'universities'), (1, 'underlying'), (1, 'undeniable'), (1, 'turn'), (1, 'trust'), (1, 'torey'), (1, 'tidy'), (1, 'things'), (1, 'theaters'), (1, 'tend'), (1, 'systemic'), (1, 'systematically'), (1, 'surveyors'), (1, 'surprise'), (1, 'suffer'), (1, 'suburbs'), (1, 'subjected'), (1, 'stop'), (1, 'status'), (1, 'startling'), (1, 'standard'), (1, 'stage'), (1, 'specific'), (1, 'spaces'), (1, 'sites'), (1, 'shocked'), (1, 'shaping'), (1, 'shaped'), (1, 'severe'), (1, 'selling'), (1, 'segregationist'), (1, 'sanctioned'), (1, 'salons'), (1, 'rose'), (1, 'role'), (1, 'robert'), (1, 'riskiness'), (1, 'revelation'), (1, 'return'), (1, 'retailers'), (1, 'residents'), (1, 'researcher'), (1, 'reported'), (1, 'remains'), (1, 'rejected'), (1, 'regions'), (1, 'reason'), (1, 'real'), (1, 'ready'), (1, 'rated'), (1, 'rate'), (1, 'ranked'), (1, 'range'), (1, 'ramifications'), (1, 'raise'), (1, 'race'), (1, 'quoting'), (1, 'pushed'), (1, 'published'), (1, 'projects'), (1, 'project'), (1, 'professor'), (1, 'private'), (1, 'previously'), (1, 'preterm'), (1, 'predominantly'), (1, 'predictable'), (1, 'predicament'), (1, 'poorer'), (1, 'pollution'), (1, 'point'), (1, 'played'), (1, 'place'), (1, 'pattern'), (1, 'past'), (1, 'partner'), (1, 'particularly'), (1, 'parks'), (1, 'parents'), (1, 'paint'), (1, 'owners'), (1, 'overwhelmingly'), (1, 'outlawed'), (1, 'originated'), (1, 'online'), (1, 'ongoing'), (1, 'official'), (1, 'obesity'), (1, 'number'), (1, 'notes'), (1, 'note'), (1, 'non'), (1, 'new'), (1, 'negroes'), (1, 'negative'), (1, 'nearly'), (1, 'near'), (1, 'nationwide'), (1, 'nancy'), (1, 'movie'), (1, 'moved'), (1, 'mortgages'), (1, 'mold'), (1, 'miles'), (1, 'miami'), (1, 'metropolitan'), (1, 'meier'), (1, 'medical'), (1, 'massachusetts'), (1, 'marked'), (1, 'mapped'), (1, 'makes'), (1, 'make'), (1, 'm'), (1, 'lot'), (1, 'looks'), (1, 'look'), (1, 'long'), (1, 'located'), (1, 'loaning'), (1, 'loan'), (1, 'lived'), (1, 'little'), (1, 'lisa'), (1, 'linking'), (1, 'lingering'), (1, 'levels'), (1, 'left'), (1, 'led'), (1, 'leaving'), (1, 'lead'), (1, 'later'), (1, 'late'), (1, 'large'), (1, 'know'), (1, 'juxtaposes'), (1, 'johns'), (1, 'jason'), (1, 'intergenerational'), (1, 'infiltration'), (1, 'industrial'), (1, 'individual'), (1, 'indicators'), (1, 'important'), (1, 'impacting'), (1, 'immigrant'), (1, 'illustrated'), (1, 'hypertension'), (1, 'house'), (1, 'hotter'), (1, 'hopkins'), (1, 'homes'), (1, 'historian'), (1, 'high'), (1, 'helen'), (1, 'healthy'), (1, 'hazards'), (1, 'harvard'), (1, 'happened'), (1, 'h'), (1, 'grew'), (1, 'green'), (1, 'great'), (1, 'graphics'), (1, 'got'), (1, 'goodbye'), (1, 'global'), (1, 'girl'), (1, 'galeano'), (1, 'fruit'), (1, 'followed'), (1, 'focuses'), (1, 'federally'), (1, 'fares'), (1, 'fair'), (1, 'factors'), (1, 'fabric'), (1, 'explore'), (1, 'explain'), (1, 'experience'), (1, 'exercise'), (1, 'examined'), (1, 'evaluate'), (1, 'especially'), (1, 'epidemiology'), (1, 'epidemiologist'), (1, 'ended'), (1, 'emphasize'), (1, 'effects'), (1, 'eduardo'), (1, 'economic'), (1, 'east'), (1, 'downhill'), (1, 'documents'), (1, 'disturbing'), (1, 'disparities'), (1, 'diseases'), (1, 'discrimination'), (1, 'discouraged'), (1, 'disappeared'), (1, 'disadvantage'), (1, 'digitized'), (1, 'differently'), (1, 'didn'), (1, 'diagnoses'), (1, 'deteriorate'), (1, 'depression'), (1, 'demographics'), (1, 'decisions'), (1, 'day'), (1, 'damage'), (1, 'cut'), (1, 'current'), (1, 'credit'), (1, 'country'), (1, 'corporation'), (1, 'corner'), (1, 'conducive'), (1, 'concentration'), (1, 'concentrate'), (1, 'compared'), (1, 'commonwealth'), (1, 'common'), (1, 'comments'), (1, 'come'), (1, 'combined'), (1, 'coded'), (1, 'code'), (1, 'classified'), (1, 'cited'), (1, 'cheap'), (1, 'characteristics'), (1, 'chan'), (1, 'challenges'), (1, 'cement'), (1, 'cases'), (1, 'cancer'), (1, 'called'), (1, 'bushes'), (1, 'built'), (1, 'build'), (1, 'born'), (1, 'body'), (1, 'bloomberg'), (1, 'births'), (1, 'better'), (1, 'beauty'), (1, 'banks'), (1, 'bank'), (1, 'baked'), (1, 'away'), (1, 'attitudes'), (1, 'asthma'), (1, 'aren'), (1, 'area'), (1, 'arc'), (1, 'americans'), (1, 'allow'), (1, 'alcohol'), (1, 'ago'), (1, 'age'), (1, 'aftermath'), (1, 'actors'), (1, 'act'), (1, '61'), (1, '60'), (1, '30'), (1, '23223'), (1, '21'), (1, '2016'), (1, '20'), (1, '1970s'), (1, '1968'), (1, '142'), (1, '')]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# I am stopping here.  Every time I try something for B it breaks and prodocues an error for A.\r\n",
    "\r\n",
    "# B. Printing the top five most frequent words from your data\r\n",
    "\r\n",
    "\r\n",
    "# C. Querying for certain key words and printing their frequency\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# D. Comparing the relative frequency of words of interest\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "db64136dc4130c2dda380bc0ce411ffaa0317e9a9f99d4dbeea1fc56cb102fad"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}