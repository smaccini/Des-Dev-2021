{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Week 3 Step 1\r\n",
    "# Start by setting up your content import. You can use the same target content as you used for exercise two, or set up something new. Read in and store the content from a single URL.\r\n",
    "\r\n",
    "\r\n",
    "# using same boilerplate and file from Week 2  \r\n",
    "import urllib.request, urllib.error, urllib.parse\r\n",
    "\r\n",
    "url = 'https://www.npr.org/sections/health-shots/2020/11/19/911909187/in-u-s-cities-the-health-effects-of-past-housing-discrimination-are-plain-to-see'\r\n",
    "\r\n",
    "response = urllib.request.urlopen(url)\r\n",
    "webContent = response.read()\r\n",
    "\r\n",
    "f = open('NPRarticleWeek3.html', 'wb')\r\n",
    "f.write(webContent)\r\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Week 3 Step 2\r\n",
    "# Next, splice the content you've imported to include only the primary text of interest. \r\n",
    "# You'll need to investigate the website you are looking at and choose strategically what tags you look for to define the starting and ending location of your splice. \r\n",
    "# Build on the model in CleaningHTML.ipynb\r\n",
    "\r\n",
    "# looking at source code of web page to find where to \"crop\" the content to trim to highlight only what is important\r\n",
    "\r\n",
    "# the startLoc is in line 542 and the endLoc is in line 924\r\n",
    "\r\n",
    "# make sure this line is creating a string based on the variable created above\r\n",
    "contents = str(webContent)\r\n",
    "startLoc = contents.find(\"<p>Torey Edmonds has lived\")\r\n",
    "endLoc = contents.find(\"see you later.\")\r\n",
    "\r\n",
    "# printing the start location/end location in numbers.  if -1, the term does not exist\r\n",
    "print(startLoc)\r\n",
    "print(endLoc)\r\n",
    "\r\n",
    "# overwriting contents file\r\n",
    "contents = contents[startLoc: endLoc]\r\n",
    "print(contents[0: 500])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "46756\n",
      "81560\n",
      "<p>Torey Edmonds has lived in the same house in an African-American neighborhood of the East End of Richmond, Va., for all of her 61 years. When she was a little girl, she says her neighborhood was a place of tidy homes with rose bushes and fruit trees, and residents had ready access to shops like beauty salons, movie theaters and several grocery stores.</p>   <p>But as she grew up, she says, the neighborhood went downhill. By the 1970s, stores had disappeared; those that did return were corner \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Week 3 Step 3\r\n",
    "\r\n",
    "# Implement a loop to remove all the HTML tags from your text. \r\n",
    "# Use the model provided in CleaningHTML.ipynb, and make sure to store your cleaned text as a string. \r\n",
    "# Print the string and inspect the results. \r\n",
    "# Save your now  cleaned text as a .txt file with an appropriate name.\r\n",
    "\r\n",
    "# loop command to eliminate the html code\r\n",
    "# use what we know about html tags, i.e. that they start with <\r\n",
    "# loop will look for < and > to elimiate what is inside\r\n",
    "\r\n",
    "# checking to see if each character is inside < and then if it is the > or inside the >  and then if outside tag\r\n",
    "\r\n",
    "\r\n",
    "inside = 0\r\n",
    "text = ''\r\n",
    "\r\n",
    "for char in contents:\r\n",
    "    if char == '<':\r\n",
    "        inside = 1\r\n",
    "    elif (inside == 1 and char == '>'):\r\n",
    "        inside = 0\r\n",
    "    elif inside== 1:\r\n",
    "        continue\r\n",
    "    else: \r\n",
    "        text += char\r\n",
    "\r\n",
    "print(text[0: 500])\r\n",
    "\r\n",
    "# still not perfect but better\r\n",
    "# can continue to add loops to eliminate other characters\r\n",
    "\r\n",
    "f = open('NPRarticleWeek3.txt','w')\r\n",
    "f.write(text)\r\n",
    "f.close()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Torey Edmonds has lived in the same house in an African-American neighborhood of the East End of Richmond, Va., for all of her 61 years. When she was a little girl, she says her neighborhood was a place of tidy homes with rose bushes and fruit trees, and residents had ready access to shops like beauty salons, movie theaters and several grocery stores.   But as she grew up, she says, the neighborhood went downhill. By the 1970s, stores had disappeared; those that did return were corner shops sell\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Week 3 Bonus Challenge\r\n",
    "\r\n",
    "# As your bonus challenge for this week, identify at least one other area of content that needs cleaning from your file: \r\n",
    "# this might be URLs, {} content, special characters, or other \"noise\" you want to cut from your spring. \r\n",
    "# Using a combination of loops, conditionals, and string methods as appropriate, remove those elements from the text.\r\n",
    "\r\n",
    "# open the txt file to read it\r\n",
    "f = open(\"NPRarticleWeek3.txt\",\"r\")\r\n",
    "\r\n",
    "# create new variable with contents\r\n",
    "NPRtext = f.read()\r\n",
    "print(NPRtext[0:1000])\r\n",
    "f.close()\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Torey Edmonds has lived in the same house in an African-American neighborhood of the East End of Richmond, Va., for all of her 61 years. When she was a little girl, she says her neighborhood was a place of tidy homes with rose bushes and fruit trees, and residents had ready access to shops like beauty salons, movie theaters and several grocery stores.   But as she grew up, she says, the neighborhood went downhill. By the 1970s, stores had disappeared; those that did return were corner shops selling cheap alcohol but \"no real food,\" Edmonds says. Houses declined too, as homeowners \\xe2\\x80\\x93 including her parents \\xe2\\x80\\x93 were rejected for loans.   \"If the bank\\'s not loaning, she says, \"then things deteriorate.\"   Today, Edmonds\\' neighborhood remains overwhelmingly African-American, with a poverty rate of nearly 60%. Many of her neighbors suffer chronic medical conditions like kidney disease and diabetes.   \"They age differently,\" says Edmonds, who works for Virginia Commonwealt\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Bonus Challenge Continued\r\n",
    "\r\n",
    "# (Find)/Replace to eliminate \\n \"Enlarge this image\" and \"Max Posner for NPR\"\r\n",
    "\r\n",
    "NPRtextcleaned = NPRtext.replace(\"Max Posner for NPR\", \" \")\r\n",
    "NPRtextcleaned = NPRtextcleaned.replace(\"\\n\", \" \")\r\n",
    "NPRtextcleaned = NPRtextcleaned.replace(\"Enlarge this image\", \" \")\r\n",
    "\r\n",
    "\r\n",
    "print(NPRtextcleaned[0:1000])\r\n",
    "\r\n",
    "\r\n",
    "f = open('NPRarticlecleaned.txt','w')\r\n",
    "f.write(text)\r\n",
    "f.close()\r\n",
    "\r\n",
    "\r\n",
    "# did not work!!!!!"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Torey Edmonds has lived in the same house in an African-American neighborhood of the East End of Richmond, Va., for all of her 61 years. When she was a little girl, she says her neighborhood was a place of tidy homes with rose bushes and fruit trees, and residents had ready access to shops like beauty salons, movie theaters and several grocery stores.   But as she grew up, she says, the neighborhood went downhill. By the 1970s, stores had disappeared; those that did return were corner shops selling cheap alcohol but \"no real food,\" Edmonds says. Houses declined too, as homeowners \\xe2\\x80\\x93 including her parents \\xe2\\x80\\x93 were rejected for loans.   \"If the bank\\'s not loaning, she says, \"then things deteriorate.\"   Today, Edmonds\\' neighborhood remains overwhelmingly African-American, with a poverty rate of nearly 60%. Many of her neighbors suffer chronic medical conditions like kidney disease and diabetes.   \"They age differently,\" says Edmonds, who works for Virginia Commonwealt\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Week 3 Step 5\r\n",
    "# Now we're ready to analyze our text. \r\n",
    "# This time, try combining the elements we've used so far to handle our text by writing a simple algorithm following this model:\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# Before I do anything, I am changing all words to lower case\r\n",
    "\r\n",
    "NPRcleanedlower = NPRtextcleaned.lower()\r\n",
    "print(NPRcleanedlower[0:100])\r\n",
    "\r\n",
    "# First, split your string into a \"bag of words\" by cutting at the whitespace into an array.\r\n",
    "\r\n",
    "# split can be used within anything you want, this would create a \"bag of words\" by splitting the string at the spaces\r\n",
    "# converting it into an array\r\n",
    "# watch - punctuation picked up\r\n",
    "\r\n",
    "NPRBagOfWords = NPRcleanedlower.split(\" \")\r\n",
    "print(NPRBagOfWords[0:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torey edmonds has lived in the same house in an african-american neighborhood of the east end of ric\n",
      "['torey', 'edmonds', 'has', 'lived', 'in', 'the', 'same', 'house', 'in', 'an', 'african-american', 'neighborhood', 'of', 'the', 'east', 'end', 'of', 'richmond,', 'va.,', 'for', 'all', 'of', 'her', '61', 'years.', 'when', 'she', 'was', 'a', 'little', 'girl,', 'she', 'says', 'her', 'neighborhood', 'was', 'a', 'place', 'of', 'tidy', 'homes', 'with', 'rose', 'bushes', 'and', 'fruit', 'trees,', 'and', 'residents', 'had', 'ready', 'access', 'to', 'shops', 'like', 'beauty', 'salons,', 'movie', 'theaters', 'and', 'several', 'grocery', 'stores.', '', '', 'but', 'as', 'she', 'grew', 'up,', 'she', 'says,', 'the', 'neighborhood', 'went', 'downhill.', 'by', 'the', '1970s,', 'stores', 'had', 'disappeared;', 'those', 'that', 'did', 'return', 'were', 'corner', 'shops', 'selling', 'cheap', 'alcohol', 'but', '\"no', 'real', 'food,\"', 'edmonds', 'says.', 'houses', 'declined']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Week 3 Step 5 Continued\r\n",
    "\r\n",
    "# Next, create a loop that runs through every word in your new array\r\n",
    "\r\n",
    "# Within the loop, create some conditionals and behaviors to process the words. \r\n",
    "# For instance, you might print out every word that starts with a certain letter, or print out words longer than a set length, etc. \r\n",
    "# Try playing with the loop breaks and continue options to handle different types of words differently.\r\n",
    "\r\n",
    "\r\n",
    "# Creating a loop - running the loop as many times as needed\r\n",
    "# for is used when there is a defined set of \"things\" - in this case an array\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "for word in NPRBagOfWords:\r\n",
    "    if word == \"redlining\":\r\n",
    "        print(word + \" yes\")\r\n",
    "\r\n",
    "for word in NPRBagOfWords:\r\n",
    "    if word == \"discrimination\":\r\n",
    "        print(\"of course discrimination is mentioned here\")\r\n",
    "        break\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "redlining yes\n",
      "of course discrimination is mentioned here\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "db64136dc4130c2dda380bc0ce411ffaa0317e9a9f99d4dbeea1fc56cb102fad"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}